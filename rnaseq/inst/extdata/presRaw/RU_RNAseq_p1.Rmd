---
title: "Analysis of RNAseq data in R and Bioconductor (part 1)<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
subtitle: " <html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html> Bioinformatics Resource Center - Rockefeller University"
author: 
  - "http://rockefelleruniversity.github.io/RU_RNAseq/"
  - "brc@rockefeller.edu"
output: 
  xaringan::moon_reader:
    css: ["default.css", "metropolisCustom.css", "metropolis-fontsCustom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [middle, inverse]
  html_document:
    toc: true # table of content true
    toc_float: yes
    depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: false  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
params:
  isSlides: "no"
---

```{r,include=FALSE}
suppressPackageStartupMessages(require(knitr))
knitr::opts_chunk$set(echo = TRUE, tidy = T)

# condaSalmon <- CondaSysReqs::install_CondaTools("salmon","salmon")
# pathToSalmon <- file.path(dirname(dirname(condaSalmon$pathToConda)),"envs",condaSalmon$environment,"bin","salmon")

```

```{r, echo=F, eval=F}
if(!file.exists("~/ENCFF332KDA.fastq.gz")){
  download.file("https://www.encodeproject.org/files/ENCFF332KDA/@@download/ENCFF332KDA.fastq.gz","~/ENCFF332KDA.fastq.gz")
}
# if(!file.exists("~/ENCFF070QMF.fastq.gz")){
#   download.file("https://www.encodeproject.org/files/ENCFF070QMF/@@download/ENCFF070QMF.fastq.gz","~/ENCFF070QMF.fastq.gz")
# }

```

```{r, results='asis',include=TRUE,echo=FALSE}
if(params$isSlides != "yes"){
  cat("# RNAseq (part 1)

---
"    
  )
  
}

```

## RNAseq

RNAseq offers a method to simultaneously measure the genome wide expression of annotated and novel transcripts.
<div align="center">
<img src="imgs/overview.png" alt="igv" height="400" width="500">
</div>

---
## Bulk RNAseq vs single cell RNAseq

scRNA-seq allows for the capture of heterogeneity in a sample
bulk RNA-seq measures average expression across the whole sample

When to use bulk RNA-seq:
    - You want to see changes between conditions and cell type information is not required
    - When higher sequencing depth is required to detect lowly expressed genes 
    - You want to study splicing or isoform-level differences 

---
## RNAseq for differential gene expression

A common goal in RNAseq is to identify genes and/or transcripts which are expressed at differing levels between our user defined sample groups.

Absolute quantification of the expression level of gene is subject to measurement biases (GC bias in PCR and/or RNA capture/selection) so it is most appropriate to compare the levels of the expression of same gene across conditions than to compare differing genes' expression levels within a condition. 

This commonly referred to as differential gene or transcript expression (DGE/DTE).

<div align="center">
<img src="imgs/dge.png" alt="igv" height="200" width="600">
</div>

---
## RNAseq for differential transcript usage

A less frequent but important goal in RNAseq is to identify any changes in the relative abundance of transcripts for a gene between conditions. This may be able to identify changes in a genes' functional role between conditions i.e. one isoform of a protein may bind and activate, another may simply bind and obstruct other active forms. We call this differential transcript usage (DTU).

<div align="center">
<img src="imgs/dtu.png" alt="igv" height="200" width="600">
</div>


---
## What we will cover

* Session 1: Alignment and counting

* Session 2: Differential gene expression analysis

* Session 3: Visualizing results through PCA and clustering

* Session 4: Gene Set Analysis

* Session 5: Differential Transcript Utilization analysis

---
## The data

Over these sessions we will review data from Christina Leslie's lab at MSKCC on T-Reg cells. This can be found on the Encode portal. T-Reg data [here](https://www.encodeproject.org/experiments/ENCSR486LMB/) and activated T-Reg data [here](https://www.encodeproject.org/experiments/ENCSR726DNP/).

---
## The data

Several intermediate files have already been made for you to use. You can download the course content from GitHub [here](https://github.com/RockefellerUniversity/RU_RNAseq/archive/master.zip). Once downloaded you will need to unzip the folder and then navigate into the *r_course* directory of the download. This will mean the paths in the code are correct.

```{r, eval=F}
setwd("Path/to/Download/RU_RNAseq-master")


```

---
```{r, results='asis',include=TRUE,echo=FALSE}
if(params$isSlides == "yes"){
  cat("class: inverse, center, middle

# Working with raw RNAseq data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=720px></html> 

---
"    
  )
}else{
  cat("# Working with raw RNAseq data

---
"    
  )
  
}

```


## Working with raw RNAseq data

FASTQ data can be directly read into R with the [ShortRead package](https://bioconductor.org/packages/release/bioc/html/ShortRead.html) to review sequence data quality. We have covered how to work with raw sequencing data in the [**FASTQ in Bioconductor** session.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/r_course/presentations/slides/FastQInBioconductor.html#1). 

Reading everything into R can take a lot of time and memory. Most times we just want to do some QC and maybe filter out low quality reads or trim. To do this in a fast or simple manner we can use the [*Rfastp*](https://bioconductor.org/packages/release/bioc/html/Rfastp.html) package.


```{r shortreada,include=FALSE}
library(ShortRead)
library(Rfastp)
library(ggplot2)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)
```
---
## Rfastp

- Trims low-quality bases from the 5′ and 3′ ends using a sliding window approach

- Automatically detects and removes adapters

- Corrects mismatched bases in overlapping regions of paired-end reads (based on quality)

- Trims polyA/polyX tails from the 3′ ends, depending on library type

- Filters out low-quality reads based on user-defined thresholds

---
## Our FASTQ file

We can download the full FASTQ using this R code. 

```{r tregFQ1, eval=F, echo=T}

fq<-"https://www.encodeproject.org/files/ENCFF332KDA/@@download/ENCFF332KDA.fastq.gz"
download.file(fq, "ENCFF332KDA.fastq.gz")

```

Alternatively a subset is available in the data directory: *data/ENCFF332KDA_sampled.fastq.gz*

---
## Rfastp

To run QC with Rfastp, we just need to use the *rfastp()* function on our FASTQ file. We also need to provide the prefix we want for the outputs to *outputFastq*. 

```{r}
json_report <- rfastp(read1 = "data/ENCFF332KDA_sampled.fastq.gz", outputFastq = "ENCFF332KDA_rfastp")
```

---
## Rfastp outputs

Running RfastP creates several files:

1. XXX_R1.fastq.gz - FASTQ with poor quality reads filtered out
2. XXX.html - HTML file contains a QC report
3. XXX.json - JSON file with all the summary statistics

```{r tregShow,eval=T, echo=F}
dir(pattern = "ENCFF332KDA_rfastp")
```


---
## Rfastp outputs in R

The object saved in R is in json format. There are several functions that allow you to extract the information out into a more readable format such as the **qcSummary()** function. This details the Before/After stats.

```{r}
qcSummary(json_report)
```


---

## Rfastp - Base Quality

The curvePlot function can also be used to plot specific QC aspects like base quality and GC content. 

```{r}

curvePlot(json_report)
```

---
## Rfastp - GC content
 
```{r}
curvePlot(json_report, curve="content_curves")

```


---
## Rfastp, trimming and more

There are a lot of options for the *rfastp()* function that allow you to customize filtering, trimming and more.

```{r}
?rfastp

```

---
## Example of custom filter usage

- Data from: ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR458/ERR458755/ERR458755.fastq.gz or load from data folder

```{r}

json_report <- rfastp(read1 = "data/ERR458755.fastq.gz", outputFastq = "ERR458755_rfastp")
```

---

## Rfastp - Base Quality

```{r}

curvePlot(json_report)
```

---
## Rfastp - GC content
 
- N content indicates low confidence when calling bases
- GC content is higher at the front end of the read

```{r}
curvePlot(json_report, curve="content_curves")

```
---

## Adding filters

- Let's filter out the first 10 bases using "trimFrontRead1"

```{r}

json_report <- rfastp(read1 = "data/ERR458755.fastq.gz", outputFastq = "ERR458755_rfastp", trimFrontRead1 = 10)
```

---

## Rfastp - Base Quality

- Notice low quality bases are eliminated at the start

```{r}

curvePlot(json_report)
```

---
## Rfastp - GC content
 
Trimming removes low-quality bases and ambiguous N bases, which can skew GC content at the 5′ end of reads

  - This can normalize GC distribution, improving downstream alignment and quantification

But: What threshold defines abnormal GC content?
  - No strict cutoff — depends on organism, library prep, and sequencing platform


```{r}
curvePlot(json_report, curve="content_curves")

```

--

## Another option to review quality: FastQC

Quality control tool for high throughput sequence data written in Java
Download here: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/
View report example here: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/bad_sequence_fastqc.html


---

## Other options to perform QC

- Trimmomatic - Tool written in Java for filtering Illumina NGS data 
     - Download here: http://www.usadellab.org/cms/index.php?page=trimmomatic
     - Can filter Illumina adapters, N bases and low quality bases 
- Cutadapt - Tool written in Python for custom filtering of reads
    - Download here: https://cutadapt.readthedocs.io/en/stable/
    - Used for filtering adapter sequences, primers and poly-A tails

---
```{r, results='asis',include=TRUE,echo=FALSE}
if(params$isSlides == "yes"){
  cat("class: inverse, center, middle

# Aligning RNAseq data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=720px></html> 

---
"    
  )
}else{
  cat("# Aligning RNAseq data

---
"    
  )
  
}

```

## Aligning RNAseq reads

Following assessment of read quality, we will want to align our reads to the genome taking into account splice junctions.

Not all RNAseq reads will align continuously against our reference genome. Instead they will map across splice junctions, so we need to use [splice aware aligners, that we have seen in previous sessions.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/r_course/presentations/slides/AlignmentInBioconductor.html#6) The resulting BAM file will contain aligned sequence reads for use in further analysis.

<div align="center">
<img src="imgs/sam2.png" alt="igv" height="200" width="600">
</div>

---
## Creating a reference genome

First we need to retrieve the sequence information for the genome of interest in [FASTA format.](https://rockefelleruniversity.github.io/Genomic_Data/presentations/slides/GenomicsData.html#9)

We can use the [BSgenome libraries to retrieve the full sequence information.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/SequencesInBioconductor.html#4)

For the mouse mm10 genome we load the package **BSgenome.Mmusculus.UCSC.mm10**.

```{r fa1q, include=FALSE}
library(BSgenome.Mmusculus.UCSC.mm10)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)
```

```{r fa1, echo=TRUE}
library(BSgenome.Mmusculus.UCSC.mm10)
BSgenome.Mmusculus.UCSC.mm10
```

---
## Creating a reference genome

We will only use the major chromosomes for our analysis so we may exclude random and unplaced contigs.
Here we cycle through the major chromosomes and create a [**DNAStringSet** object from the retrieved sequences](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/SequencesInBioconductor.html#22).

```{r fa2,cache=FALSE,echo=TRUE}
mainChromosomes <- paste0("chr",c(1:19,"X","Y","M"))
mainChrSeq <- lapply(mainChromosomes,
                     function(x) BSgenome.Mmusculus.UCSC.mm10[[x]])
names(mainChrSeq) <- mainChromosomes
mainChrSeqSet <- DNAStringSet(mainChrSeq)
mainChrSeqSet
```

---
## Creating a reference genome

Now we have a **DNAStringSet** object we can use the [**writeXStringSet** to create our FASTA file of sequences to align to.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/SequencesInBioconductor.html#22)

```{r fa3, echo=TRUE,eval=FALSE}

writeXStringSet(mainChrSeqSet,
                "BSgenome.Mmusculus.UCSC.mm10.mainChrs.fa")
```

---

## Other available genomes

```{r, eval = T}
BiocManager::install("BSgenome")
library(BSgenome)
available.genomes()

```

---
## Creating an Rsubread index 

We will be aligning using the **subjunc** algorithm from the folks behind subread. We can therefore use the **Rsubread** package. Before we attempt to align our FASTQ files, we will need to first build an index from our reference genome using the **buildindex()** function.

The [**buildindex()** function simply takes the parameters of our desired index name and the FASTA file to build index from.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/AlignmentInBioconductor.html#14)

REMEMBER: Building an index is memory intensive and by default is set to 8GB. This may be too large for your laptop or desktop computer. 

```{r, echo=TRUE,eval=FALSE}
library(Rsubread)
buildindex("mm10_mainchrs",
           "BSgenome.Mmusculus.UCSC.mm10.mainChrs.fa", 
           memory=8000,
           indexSplit=TRUE)

```

---
## Why index?

Indexing involves creating a lookup table of k-mers (short DNA sequences of length k) across the genome

This enables fast, memory-efficient search and alignment by avoiding full genome scans

---
## Rsubread RNAseq alignment

We can align our raw sequence data in FASTQ format to the new FASTA file of our mm10 genome sequence using the **Rsubread** package. Specifically we will be using the **subjunc** function as it is splice aware. This means it will detect reads that span introns. This is the major difference between alignment of RNAseq and other genomic technologies like DNAseq and ChIPseq where we will use the align function. 

We can also provide a SAF or GTF to our Rsubread call. Although largely unnecessary for gene expression estimation, this will allow us to capture non-canonical splice sites.

We simply need to provide a SAF/gtf to **annot.ext** parameter and set **useAnnotation** and **isGTF** to FALSE/TRUE depending on whether we use SAF or GTF as external data.

---
## SAF format using exons()

SAF format is used by Rsubread to hold feature information. We simply need a table of exons' chromosome locations (chromosome,start,end,strand) and a feature/metafeature ID.

We can retrieve exon locations and their gene ids using **exons()** function. We further select only exons which are annotated to exactly 1 gene.

```{r, echo=TRUE, eval=TRUE}
library(TxDb.Mmusculus.UCSC.mm10.knownGene)
myExons <- exons(TxDb.Mmusculus.UCSC.mm10.knownGene,columns=c("tx_id","gene_id"))
myExons <- myExons[lengths(myExons$gene_id) == 1]
myExons
```

---
## SAF format

With the exons GRanges we can create the appropriate data.frame of SAF format for Rsubread.

```{r SAF, echo=TRUE, eval=F}
dfExons <- as.data.frame(myExons)
SAF <- data.frame(GeneID=dfExons$gene_id,
                  Chr=dfExons$seqnames,
                  Start=dfExons$start,
                  End=dfExons$end,
                  Strand=dfExons$strand)
```

---
## RNA alignment with external annotation

Now we have our SAF formatted exon information we can provide the SAF data.frame to the **annot.ext** argument, set **isGTF** as FALSE and set **useAnnotation** to TRUE.

```{r, echo=TRUE, eval=FALSE}

myMapped <- subjunc("mm10_mainchrs",
                    "ENCFF332KDA.fastq.gz",
                    output_format = "BAM",
                    output_file = "Treg_1.bam",
                    useAnnotation = TRUE,
                    annot.ext = SAF,
                    isGTF=FALSE,
                    nthreads = 4)

```

---

## Using GENCODE database with TxDb

```{r, echo = T, eval = F}

library(GenomicFeatures)

# Download the GTF 
gtf_url <- "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/gencode.v31.annotation.gtf.gz"

# Name of GTF file
gtf_file <- "gencode.v31.annotation.gtf.gz"

if (!file.exists(gtf_file)) {
  download.file(gtf_url, destfile = gtf_file)
}

# Create TxDb object
TxDb <- makeTxDbFromGFF(
  file = gtf_file,
  format = "gtf",
  organism = "Homo sapiens",
  chrominfo = NULL,
  circ_seqs = "chrM"
)

# Filter and keep desired chromosomes
keep_chrs <- paste0("chr", c(seq_len(22), "X", "Y", "M"))
TxDb <- keepSeqlevels(TxDb, keep_chrs, pruning.mode = "coarse")

```

---
## Sort and index reads

As before, we sort and index our files using the [**Rsamtools** packages **sortBam()** and **indexBam()** functions respectively.](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/AlignedDataInBioconductor.html#11)

The resulting sorted and indexed BAM file is now ready for use in external programs such as IGV as well as for further downstream analysis in R.


```{r sortindex, echo=TRUE, eval=FALSE}
library(Rsamtools)
sortBam("Treg_1.bam","Sorted_Treg_1")
indexBam("Sorted_Treg_1.bam")
```

<div align="center">
<img src="imgs/alignedData.png" alt="igv" height="200" width="600">
</div>


---
```{r, results='asis',include=TRUE,echo=FALSE}
if(params$isSlides == "yes"){
  cat("class: inverse, center, middle

# Counting with aligned RNAseq data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=720px></html> 

---
"    
  )
}else{
  cat("# Counting with aligned RNAseq data

---
"    
  )
  
}

```

## Counting in gene models

With our newly aligned reads it is now possible to assign reads to genes in order to quantify a genes' expression level (as reads) within a sample. 

First we need to gather our gene models of exons and splice junctions which we can use in our later counting steps.

```{r gm, echo=TRUE,eval=TRUE,cache=TRUE}
library(TxDb.Mmusculus.UCSC.mm10.knownGene)
geneExons <- exonsBy(TxDb.Mmusculus.UCSC.mm10.knownGene,by="gene")
class(geneExons)
```

---
## Counting in gene models

Now we have our GRangesList with each entry corresponding to a gene and within each entry a GRanges object of the genes' exons.

```{r gm2,echo=TRUE,eval=TRUE,cache=TRUE,dependson="gm"}
geneExons[1:2]
```

---
## Counting in gene models

We can now use the **summarizeOverlaps()** to [count the reads in our BAM that overlap genes](https://rockefelleruniversity.github.io/Bioconductor_Introduction/presentations/slides/Summarising_Scores_In_Bioconductor.html#30). We specify a BamFile object using the **BamFile()** function and specifying the **yieldSize** parameter to 10000  to control memory footprint.

The resulting **RangedSummarizedExperiment** object containing our counts and **GRanges** object.


```{r gm0,echo=TRUE,eval=F}
library(GenomicAlignments)
myBam <- BamFile("Sorted_Treg_1.bam",yieldSize = 10000)
tregGeneCounts <- summarizeOverlaps(geneExons,myBam,
                                    ignore.strand = TRUE)
tregGeneCounts
```

```{r gm3,echo=FALSE,eval=TRUE,cache=TRUE}
load("data/myTregCounts2020.RData")
tregGeneCounts
```


---
## Counting in exons models

If want to start to evaluate differential transcript usage we will often evaluate counts over exons and assess for changes in exon usage.

<div align="center">
<img src="imgs/dtu.png" alt="igv" height="300" width="600">
</div>

---
## Counting in exons models

To count over exons however we will encounter an issue of assigning reads to overlapping exons.

<div align="center">
<img src="imgs/overExons.png" alt="igv" height="300" width="600">
</div>

---
## Counting in exons models

We can then work to differentiate exons by collapsing exons to the nonoverlapping, disjoint regions.

<div align="center">
<img src="imgs/overExons_Disjoint.png" alt="igv" height="300" width="600">
</div>



---
## Counting in exons models

We can use the GenomicFeatures' package's **exonicParts()** function with our TxDb object, TxDb.Mmusculus.UCSC.mm10.knownGene, to extract a GRanges of our disjoint exons with their associated **gene_id**, **tx_name**, **exonic_part** in the metadata columns.

We add some sensible names to our GRanges for use in later steps.

```{r em2,echo=TRUE,eval=T,cache=TRUE,dependson="em"}
library(GenomicFeatures)
nonOverlappingExons <- exonicParts(TxDb.Mmusculus.UCSC.mm10.knownGene, linked.to.single.gene.only=TRUE )
names(nonOverlappingExons) <-
    paste0(nonOverlappingExons$gene_id,":E", nonOverlappingExons$exonic_part)
nonOverlappingExons[1:3,]

```

---
## Counting in exons models

We can now again use the **summarizeOverlaps()** function with our nonOverlapping, disjoint exons to identify a BAM file of interest.

We need to set the **inter.feature** to FALSE to allow us to count reads overlapping multiple features (such as a read spanning between two exons).

```{r em3,echo=TRUE,eval=FALSE,cache=TRUE,dependson="em2"}
tregExonCounts <- summarizeOverlaps(nonOverlappingExons,
                                    myBam,
                                    ignore.strand = TRUE,
                                    inter.feature=FALSE)
```

---
## Counting in exons models

Now we can review our counts from our gene-level and exon-level counting. 

We retrieve a matrix of counts from either **RangedSummarizedExperiment** object using the **assay()** function.

```{r em4A,echo=FALSE,eval=TRUE,cache=TRUE}
load("data/myTregExonCounts2020.RData")
```

```{r em4,echo=TRUE,eval=TRUE,cache=TRUE,dependson=c("em4A","gm3")}
geneCounts <- assay(tregGeneCounts)
exonCounts <- assay(tregExonCounts)
head(exonCounts,2)
head(geneCounts,2)
```


---
```{r, results='asis',include=TRUE,echo=FALSE}
if(params$isSlides == "yes"){
  cat("class: inverse, center, middle

# Transcript quantification with pseudo-alignment

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=720px></html> 

---
"    
  )
}else{
  cat("# Transcript quantification with pseudo-alignment

---
"    
  )
  
}

```

## Transcript quantification

More recently methods have developed to directly quantify transcript abundance from FASTQ files using k-mer counting. 

k-mer counting offers a super fast method of gaining transcript abundance estimates, but does not produce a genomic alignment so not so useful for visualization. 

As we are most often interested in gene expression changes this offers a fast alternative to counting for alignment and counting.

The two leading pieces of software for k-mer counting

* [Salmon](http://salmon.readthedocs.io/en/latest/) - Relationship with DESeq2.
 
* [Kallisto](https://pachterlab.github.io/kallisto/about) - History of splice aware aligners and transcript quantification.

---

## Salmon

Salmon is the latest in a set of k-mer counting tools from the Kingsford lab (Jellyfish and Sailfish) and offers a workflow for transcript quantification from FASTQ raw sequencing data and a FASTA file of transcript sequences.

![](imgs/salmon.png)

---
## Installing programs that aren't in R

There is no R package for Salmon. It is possible to install it on Mac and Linux using the [Anaconda](https://anaconda.org/bioconda/salmon) package repository (unfortunately there is not a Windows implementation). Anaconda is a huge collection of version controlled packages that can be installed through the conda package management system. With conda it is easy to create and manage environments that have a variety of different packages in them. 

Though there is no Salmon R package, we can interact with the anaconda package system using the R package [Herper](https://bioconductor.org/packages/release/bioc/html/Herper.html). This was created by us here at the BRC and is part of Bioconductor.

```{r, eval=F}
BiocManager::install("Herper")
library(Herper)

```


---
## Install Salmon with Herper

First, we will use Herper to install Salmon with the *install_CondaTools* function. We just need to tell *install_CondaTools* what tool/s you want and the name of the environment you want to build. 

```{r, echo=T, eval=F}
salmon_paths <- install_CondaTools(tools="salmon", env="RNAseq_analysis")
salmon_paths
```

```{r, eval=F, echo=F}
tempdir2 <- function() {
    tempDir <- tempdir()
    if(dir.exists(tempDir)){
      tempDir <- file.path(tempDir,"rr")
    }
    tempDir <- gsub("\\", "/", tempDir, fixed = TRUE)
    tempDir
}

myMiniconda <- file.path(tempdir2(), "Test")
install_CondaTools(tools="salmon", env="RNAseq_analysis", pathToMiniConda = myMiniconda)

```

Behind the scenes, Herper will install the most minimal version of conda (called miniconda), and then will create a new environment into which Salmon will be installed. When you run the function it prints out where Salmon is installed. There are additional arguments to control where miniconda is installed using *pathToMiniConda* and also update an existing environment with *updateEnv*. 

---
## Reference for transcript quantification

Once Salmon is installed we need to make a Salmon index. First we need a FASTA file of transcript sequences. We can use the GenomicFeatures' packages **extractTranscriptSeqs** function to retrieve a DNAstringSet object of transcript sequences using our sequence data from **BSgenome.Mmusculus.UCSC.mm10** and gene models from **TxDb.Mmusculus.UCSC.mm10.knownGene** object.

```{r sal1,echo=TRUE,eval=F,cache=TRUE}
allTxSeq <- extractTranscriptSeqs(BSgenome.Mmusculus.UCSC.mm10,
                      TxDb.Mmusculus.UCSC.mm10.knownGene,
                      use.names=TRUE)
allTxSeq
```

---
## Reference for transcript quantification

With our new DNAstringSet object of transcript sequences we can write a FASTA file for use in Salmon with the **writeXStringSet** function.

```{r sal2,echo=F,eval=F,cache=TRUE,dependson="sal1"}
writeXStringSet(allTxSeq,"mm10Trans.fa")
```

```{r sal0,echo=TRUE,eval=F}
writeXStringSet(allTxSeq,
                "mm10Trans.fa")
```

---
## Reference with decoy sequences 

We can also provide a set of decoy sequences for building an index. This allows salmon to consider similar sequences outside of transcriptomic regions when mapping.

To do this we need to add the main chromosomes to our transcriptome FASTA for creating an index.

```{r sal2t,echo=T,eval=F,dependson="sal1",  cache.lazy = FALSE}
mainChromosomes <- paste0("chr",c(1:19,"X","Y","M"))
mainChrSeq <- lapply(mainChromosomes,
                     function(x)BSgenome.Mmusculus.UCSC.mm10[[x]])
names(mainChrSeq) <- mainChromosomes
mainChrSeqSet <- DNAStringSet(mainChrSeq)
gentrome <- c(allTxSeq,mainChrSeqSet)
```

---
## Reference with dummy sequence

We will also need to provide a config file containing the names of sequences to be used for decoys.

```{r sal0t,echo=TRUE,eval=F}
writeXStringSet(gentrome,
                "mm10Gentrome.fa")
write.table(as.data.frame(mainChromosomes),"decoy.txt",
            row.names = FALSE,
            col.names = FALSE,
            quote=FALSE)
```


---
## Salmon index from R

As with standard aligners, the first part of our quantification requires us to make an index from our FASTA file using the **Salmon index** command. We specify the transcript FASTA file (-t) and index name (-i).

Here we arrange our Salmon command into a system call from R. This means we are directly triggering an OS command from within R.

```{}
salmon index -i mm10Trans -t mm10Trans.fa
```

Herper allows us to run conda packages from within R. Salmon has been installed into the environment *RNAseq_analysis*. So we can use this environment from R using *with_CondaEnv()*.

```{r salI_1,echo=TRUE,eval=F,dependson="sal1", warning=F}

fastaTx <- "mm10Trans.fa"
indexName <- "mm10Trans"

with_CondaEnv("RNAseq_analysis",
                      system2(command="salmon",args = c("index",
                        "-i",indexName,
                        "-t",fastaTx),
                        
                        stdout = TRUE))

```

```{r, eval=F, echo=F, message=F, warning=F}

with_CondaEnv("RNAseq_analysis",
                      system2(command="salmon",args = c("quant", "--help-alignment"),
                        stdout = TRUE), 
              pathToMiniConda = myMiniconda)


```

---
## Salmon index from R

To create index with decoys we provide our transcriptome + chromosome FASTA as well as our decoy file to the -d paramter.

```{r salI_1t,echo=TRUE,eval=F}

with_CondaEnv("RNAseq_analysis",
                      system2(command="salmon",args = c("index",
                        "-i",indexName,
                        "-t",fastaTx,
                        "-d decoy.txt"),
                        
                        stdout = TRUE))

```



---
## Salmon quant from R

To quantify transcript abundance we use the **Salmon quant** command. 

We specify the index location (-i), the reads to quantify (-r), the output directory (-o) and the library type as automatic detection of type (-l A).

```{}
salmon quant -i mm10Trans -r ~/Downloads/ENCFF332KDA.fastq.gz -o TReg_1_Quant -l A
```

```{r salQ_1,echo=TRUE,eval=F}
fq <- "ENCFF332KDA.fastq.gz"
outDir <- "TReg_1_Quant"

with_CondaEnv("RNAseq_analysis",
                      system2(command="salmon",args = c("quant",
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq),
                        
                        stdout = TRUE))

```

```{R, eval=F, echo=F}

fq <- "data/ENCFF332KDA_sampled.fastq.gz"
outDir <- "TReg_1_Quant"

with_CondaEnv("RNAseq_analysis",
                      system2(command="salmon",args = c("quant",
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq),
                        
                        stdout = TRUE), 
              pathToMiniConda = myMiniconda)
```


```{r include=FALSE,eval=FALSE}
salmonExec <- paste0(pathToSalmon," quant")
fq <- "ENCFF001LDC.fastq.gz"
outDir <- "Liver1"
salmonQuantCmd <- paste(salmonExec,
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq)
salmonQuantCmd
system(salmonQuantCmd, wait = TRUE)

salmonExec <- paste0(pathToSalmon," quant")
fq <- "ENCFF001LCY.fastq.gz"
outDir <- "Liver2"
salmonQuantCmd <- paste(salmonExec,
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq)
salmonQuantCmd
system(salmonQuantCmd, wait = TRUE)

salmonExec <- paste0(pathToSalmon," quant")
fq <- "ENCFF001LCD.fastq.gz"
outDir <- "Heart1"
salmonQuantCmd <- paste(salmonExec,
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq)
salmonQuantCmd
system(salmonQuantCmd, wait = TRUE)

salmonExec <- paste0(pathToSalmon," quant")
fq <- "ENCFF001LCE.fastq.gz"
outDir <- "Heart2"
salmonQuantCmd <- paste(salmonExec,
                        "-i",indexName,
                        "-o",outDir,
                        "-l A",
                        "-r",fq)
salmonQuantCmd
system(salmonQuantCmd, wait = TRUE)
```


---
## Salmon outputs

The output from Salmon is our quantification of transcripts in the **quant.sf** file in the user defined output directory.

We will use a new package **tximport** to handle these counts in next session, but for now we can review file using standard data import R libraries.


```{r salReadIn,echo=TRUE,eval=FALSE,cache=TRUE}
myQuant <- read.delim("TReg_1_Quant/quant.sf")
myQuant[1:3,]
```

```{r salReadIn2,echo=FALSE,eval=TRUE,cache=TRUE}
myQuant <- read.delim("data/TReg_1_Quant/quant.sf")
myQuant[1:3,]
```

---


## Pseudoalignment with Kallisto

- Pseudoaligners like Kallisto do not align reads base-by-base
- It maps each read to the set of transcripts containing its k-mers
- It determines potential origins without full alignment

<div align="center">
<img src="imgs/pseudoalignment.png" alt="igv" height="500" width="400">
</div>



---

## When to use different tools

Traditional aligners like STAR and subjunc map reads to exact genomic locations
  - Better for detecting splicing events, novel transcripts, or structural features

Salmon performs selective alignment
  - Fast method focused on transcript quantification

Kallisto uses pseudo-alignment
  -Ultra-fast, maps reads to transcripts without full alignment
  -Does not provide genomic locations



---
## Time for an exercise


[Link_to_exercises](../../exercises/exercises/RNAseq_part1_exercise.html)

[Link_to_answers](../../exercises/answers/RNAseq_part1_answers.html)

